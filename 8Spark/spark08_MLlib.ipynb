{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLlib package of PySpark\n",
    "- spark 2.x 부터 ML 패키지는 데이터프레임에 대해 작동\n",
    "    - MLlib 패키지는 RDD에 대해 작동함\n",
    "    \n",
    "- MLlib은 전체적으로 크게 세단계의 머신러닝 기능으로 구분된다\n",
    "    1. 데이터 전처리 : \n",
    "        - 피처추출, 변형, 선택, 카테고리 피처에 대한 해석, 자연어처리\n",
    "    1. 머신러닝 알고리즘 :\n",
    "        - 몇몇 유명, 고급레벨인 회귀, 분류, 군집 알고리즘 지원\n",
    "    1. 유틸리티 :\n",
    "        - 기술통계, 카이스퀘어(ChiSquare)테스트, 선형대수, 모델평가\n",
    "        \n",
    "- https://books.google.co.kr/books?id=HVQoDwAAQBAJ&pg=PA84&lpg=PA84&dq=births_transformed+%3D+births_transformed.select(exprs_YNU)&source=bl&ots=tLNsHpKdfH&sig=ACfU3U37yj0SiQWLB-DgXvOuT1toOs4keQ&hl=ko&sa=X&ved=2ahUKEwjissX9v5HpAhWS7WEKHbfMAkIQ6AEwAHoECAoQAQ#v=onepage&q&f=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../../data/RDD_example/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=appName, master=local[2]) created by __init__ at <ipython-input-7-d75bc8a5b849>:6 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d75bc8a5b849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconf\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetAppName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'appName'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetMaster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'local[2]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msc\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    330\u001b[0m                         \u001b[1;34m\" created by %s at %s:%s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[1;32m--> 332\u001b[1;33m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[0;32m    333\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=appName, master=local[2]) created by __init__ at <ipython-input-7-d75bc8a5b849>:6 "
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf  = pyspark.SparkConf().setAppName('appName').setMaster('local[2]')\n",
    "sc    = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFANT_ALIVE_AT_REPORT 가 1인지, 0 인지를 예측 하는것이 목표\n",
    "- US 2014 ~ 2015 년 출생데이터의 일부\n",
    "    - 원본데이터는 300개의 피쳐로 구성, 그중 85개 선별\n",
    "\n",
    "- 799 만개의 데이터 중 45429개 균등 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    ('INFANT_ALIVE_AT_REPORT', typ.StringType()),\n",
    "    ('BIRTH_YEAR', typ.IntegerType()),\n",
    "    ('BIRTH_MONTH', typ.IntegerType()),\n",
    "    ('BIRTH_PLACE', typ.StringType()),\n",
    "    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n",
    "    ('MOTHER_RACE_6CODE', typ.StringType()),\n",
    "    ('MOTHER_EDUCATION', typ.StringType()),\n",
    "    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n",
    "    ('FATHER_EDUCATION', typ.StringType()),\n",
    "    ('MONTH_PRECARE_RECODE', typ.StringType()),\n",
    "    ('CIG_BEFORE', typ.IntegerType()),\n",
    "    ('CIG_1_TRI', typ.IntegerType()),\n",
    "    ('CIG_2_TRI', typ.IntegerType()),\n",
    "    ('CIG_3_TRI', typ.IntegerType()),\n",
    "    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n",
    "    ('MOTHER_BMI_RECODE', typ.IntegerType()),\n",
    "    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n",
    "    ('DIABETES_PRE', typ.StringType()),\n",
    "    ('DIABETES_GEST', typ.StringType()),\n",
    "    ('HYP_TENS_PRE', typ.StringType()),\n",
    "    ('HYP_TENS_GEST', typ.StringType()),\n",
    "    ('PREV_BIRTH_PRETERM', typ.StringType()),\n",
    "    ('NO_RISK', typ.StringType()),\n",
    "    ('NO_INFECTIONS_REPORTED', typ.StringType()),\n",
    "    ('LABOR_IND', typ.StringType()),\n",
    "    ('LABOR_AUGM', typ.StringType()),\n",
    "    ('STEROIDS', typ.StringType()),\n",
    "    ('ANTIBIOTICS', typ.StringType()),\n",
    "    ('ANESTHESIA', typ.StringType()),\n",
    "    ('DELIV_METHOD_RECODE_COMB', typ.StringType()),\n",
    "    ('ATTENDANT_BIRTH', typ.StringType()),\n",
    "    ('APGAR_5', typ.IntegerType()),\n",
    "    ('APGAR_5_RECODE', typ.StringType()),\n",
    "    ('APGAR_10', typ.IntegerType()),\n",
    "    ('APGAR_10_RECODE', typ.StringType()),\n",
    "    ('INFANT_SEX', typ.StringType()),\n",
    "    ('OBSTETRIC_GESTATION_WEEKS', typ.IntegerType()),\n",
    "    ('INFANT_WEIGHT_GRAMS', typ.IntegerType()),\n",
    "    ('INFANT_ASSIST_VENTI', typ.StringType()),\n",
    "    ('INFANT_ASSIST_VENTI_6HRS', typ.StringType()),\n",
    "    ('INFANT_NICU_ADMISSION', typ.StringType()),\n",
    "    ('INFANT_SURFACANT', typ.StringType()),\n",
    "    ('INFANT_ANTIBIOTICS', typ.StringType()),\n",
    "    ('INFANT_SEIZURES', typ.StringType()),\n",
    "    ('INFANT_NO_ABNORMALITIES', typ.StringType()),\n",
    "    ('INFANT_ANCEPHALY', typ.StringType()),\n",
    "    ('INFANT_MENINGOMYELOCELE', typ.StringType()),\n",
    "    ('INFANT_LIMB_REDUCTION', typ.StringType()),\n",
    "    ('INFANT_DOWN_SYNDROME', typ.StringType()),\n",
    "    ('INFANT_SUSPECTED_CHROMOSOMAL_DISORDER', typ.StringType()),\n",
    "    ('INFANT_NO_CONGENITAL_ANOMALIES_CHECKED', typ.StringType()),\n",
    "    ('INFANT_BREASTFED', typ.StringType())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = typ.StructType([ typ.StructField(e[0], e[1], False)\n",
    "                        for e in labels ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = spark.read.csv(base_path+'births_train.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(births)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INFANT_ALIVE_AT_REPORT: string (nullable = true)\n",
      " |-- BIRTH_YEAR: integer (nullable = true)\n",
      " |-- BIRTH_MONTH: integer (nullable = true)\n",
      " |-- BIRTH_PLACE: string (nullable = true)\n",
      " |-- MOTHER_AGE_YEARS: integer (nullable = true)\n",
      " |-- MOTHER_RACE_6CODE: string (nullable = true)\n",
      " |-- MOTHER_EDUCATION: string (nullable = true)\n",
      " |-- FATHER_COMBINED_AGE: integer (nullable = true)\n",
      " |-- FATHER_EDUCATION: string (nullable = true)\n",
      " |-- MONTH_PRECARE_RECODE: string (nullable = true)\n",
      " |-- CIG_BEFORE: integer (nullable = true)\n",
      " |-- CIG_1_TRI: integer (nullable = true)\n",
      " |-- CIG_2_TRI: integer (nullable = true)\n",
      " |-- CIG_3_TRI: integer (nullable = true)\n",
      " |-- MOTHER_HEIGHT_IN: integer (nullable = true)\n",
      " |-- MOTHER_BMI_RECODE: integer (nullable = true)\n",
      " |-- MOTHER_PRE_WEIGHT: integer (nullable = true)\n",
      " |-- MOTHER_DELIVERY_WEIGHT: integer (nullable = true)\n",
      " |-- MOTHER_WEIGHT_GAIN: integer (nullable = true)\n",
      " |-- DIABETES_PRE: string (nullable = true)\n",
      " |-- DIABETES_GEST: string (nullable = true)\n",
      " |-- HYP_TENS_PRE: string (nullable = true)\n",
      " |-- HYP_TENS_GEST: string (nullable = true)\n",
      " |-- PREV_BIRTH_PRETERM: string (nullable = true)\n",
      " |-- NO_RISK: string (nullable = true)\n",
      " |-- NO_INFECTIONS_REPORTED: string (nullable = true)\n",
      " |-- LABOR_IND: string (nullable = true)\n",
      " |-- LABOR_AUGM: string (nullable = true)\n",
      " |-- STEROIDS: string (nullable = true)\n",
      " |-- ANTIBIOTICS: string (nullable = true)\n",
      " |-- ANESTHESIA: string (nullable = true)\n",
      " |-- DELIV_METHOD_RECODE_COMB: string (nullable = true)\n",
      " |-- ATTENDANT_BIRTH: string (nullable = true)\n",
      " |-- APGAR_5: integer (nullable = true)\n",
      " |-- APGAR_5_RECODE: string (nullable = true)\n",
      " |-- APGAR_10: integer (nullable = true)\n",
      " |-- APGAR_10_RECODE: string (nullable = true)\n",
      " |-- INFANT_SEX: string (nullable = true)\n",
      " |-- OBSTETRIC_GESTATION_WEEKS: integer (nullable = true)\n",
      " |-- INFANT_WEIGHT_GRAMS: integer (nullable = true)\n",
      " |-- INFANT_ASSIST_VENTI: string (nullable = true)\n",
      " |-- INFANT_ASSIST_VENTI_6HRS: string (nullable = true)\n",
      " |-- INFANT_NICU_ADMISSION: string (nullable = true)\n",
      " |-- INFANT_SURFACANT: string (nullable = true)\n",
      " |-- INFANT_ANTIBIOTICS: string (nullable = true)\n",
      " |-- INFANT_SEIZURES: string (nullable = true)\n",
      " |-- INFANT_NO_ABNORMALITIES: string (nullable = true)\n",
      " |-- INFANT_ANCEPHALY: string (nullable = true)\n",
      " |-- INFANT_MENINGOMYELOCELE: string (nullable = true)\n",
      " |-- INFANT_LIMB_REDUCTION: string (nullable = true)\n",
      " |-- INFANT_DOWN_SYNDROME: string (nullable = true)\n",
      " |-- INFANT_SUSPECTED_CHROMOSOMAL_DISORDER: string (nullable = true)\n",
      " |-- INFANT_NO_CONGENITAL_ANOMALIES_CHECKED: string (nullable = true)\n",
      " |-- INFANT_BREASTFED: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "births.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Y : yes\n",
    "- N : no\n",
    "- U : unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recode_dictionary = {\n",
    "    'YNU' : {\n",
    "         'Y' : 1\n",
    "        ,'N' : 2\n",
    "        ,'U' : 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recode_dictionary), len(recode_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'INFANT_ALIVE_AT_REPORT', \n",
    "    'BIRTH_PLACE', \n",
    "    'MOTHER_AGE_YEARS', \n",
    "    'FATHER_COMBINED_AGE', \n",
    "    'CIG_BEFORE', \n",
    "    'CIG_1_TRI', \n",
    "    'CIG_2_TRI', \n",
    "    'CIG_3_TRI', \n",
    "    'MOTHER_HEIGHT_IN', \n",
    "    'MOTHER_PRE_WEIGHT', \n",
    "    'MOTHER_DELIVERY_WEIGHT', \n",
    "    'MOTHER_WEIGHT_GAIN', \n",
    "    'DIABETES_PRE', \n",
    "    'DIABETES_GEST', \n",
    "    'HYP_TENS_PRE', \n",
    "    'HYP_TENS_GEST', \n",
    "    'PREV_BIRTH_PRETERM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_trimmed = births.select(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INFANT_ALIVE_AT_REPORT: string (nullable = true)\n",
      " |-- BIRTH_PLACE: string (nullable = true)\n",
      " |-- MOTHER_AGE_YEARS: integer (nullable = true)\n",
      " |-- FATHER_COMBINED_AGE: integer (nullable = true)\n",
      " |-- CIG_BEFORE: integer (nullable = true)\n",
      " |-- CIG_1_TRI: integer (nullable = true)\n",
      " |-- CIG_2_TRI: integer (nullable = true)\n",
      " |-- CIG_3_TRI: integer (nullable = true)\n",
      " |-- MOTHER_HEIGHT_IN: integer (nullable = true)\n",
      " |-- MOTHER_PRE_WEIGHT: integer (nullable = true)\n",
      " |-- MOTHER_DELIVERY_WEIGHT: integer (nullable = true)\n",
      " |-- MOTHER_WEIGHT_GAIN: integer (nullable = true)\n",
      " |-- DIABETES_PRE: string (nullable = true)\n",
      " |-- DIABETES_GEST: string (nullable = true)\n",
      " |-- HYP_TENS_PRE: string (nullable = true)\n",
      " |-- HYP_TENS_GEST: string (nullable = true)\n",
      " |-- PREV_BIRTH_PRETERM: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "births_trimmed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 데이터셋에는 YES, NO, UNKNOWN 값을 가진 피쳐들이 매우 많음\n",
    "    - YES만 1, 나머지는 0으로 변환\n",
    "- 어미의 흡연량 관련 레코드 :\n",
    "    - 0      : 임신기간 동안 금연\n",
    "    - 1 ~ 97 : 1 ~ 97 개피 흡연\n",
    "    - 98     : 98개피 이상\n",
    "    - 99     : 알수없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "\n",
    "def recode(col, key):\n",
    "    return recode_dictionary[key][col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 99 : 알수없음을 제외한 것은 그대로 반환하고, 99 일때는 0을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_cig(feat):\n",
    "    return func.when(func.col(feat) != 99, func.col(feat)).otherwise(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 정의 함수 써보기\n",
    "- def 으로 정의한것을 넣어서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_integer = func.udf( recode, typ.IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_trimmed \\\n",
    "                    .withColumn('CIG_BEFORE', correct_cig('CIG_BEFORE')) \\\n",
    "                    .withColumn('CIG_1_TRI', correct_cig('CIG_1_TRI')) \\\n",
    "                    .withColumn('CIG_2_TRI', correct_cig('CIG_2_TRI')) \\\n",
    "                    .withColumn('CIG_3_TRI', correct_cig('CIG_3_TRI'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- births_trimmed.schema 에는 이름, 데이터타입, nullable 여부가 있는데\n",
    "- 이중 name, dataType만 가져오겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INFANT_ALIVE_AT_REPORT', StringType),\n",
       " ('BIRTH_PLACE', StringType),\n",
       " ('MOTHER_AGE_YEARS', IntegerType),\n",
       " ('FATHER_COMBINED_AGE', IntegerType),\n",
       " ('CIG_BEFORE', IntegerType),\n",
       " ('CIG_1_TRI', IntegerType),\n",
       " ('CIG_2_TRI', IntegerType),\n",
       " ('CIG_3_TRI', IntegerType),\n",
       " ('MOTHER_HEIGHT_IN', IntegerType),\n",
       " ('MOTHER_PRE_WEIGHT', IntegerType),\n",
       " ('MOTHER_DELIVERY_WEIGHT', IntegerType),\n",
       " ('MOTHER_WEIGHT_GAIN', IntegerType),\n",
       " ('DIABETES_PRE', StringType),\n",
       " ('DIABETES_GEST', StringType),\n",
       " ('HYP_TENS_PRE', StringType),\n",
       " ('HYP_TENS_GEST', StringType),\n",
       " ('PREV_BIRTH_PRETERM', StringType)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [ (col.name, col.dataType) for col in births_trimmed.schema ]\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Y or N 을 찾기\n",
    "    - StringType이겠네?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y', 'N']\n",
      "['INFANT_ALIVE_AT_REPORT']\n",
      "['7', '3', '5', '6', '9', '1', '4', '2']\n",
      "['Y', 'U', 'N']\n",
      "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE']\n",
      "['Y', 'U', 'N']\n",
      "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE', 'DIABETES_GEST']\n",
      "['Y', 'U', 'N']\n",
      "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE', 'DIABETES_GEST', 'HYP_TENS_PRE']\n",
      "['Y', 'U', 'N']\n",
      "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE', 'DIABETES_GEST', 'HYP_TENS_PRE', 'HYP_TENS_GEST']\n",
      "['Y', 'U', 'N']\n",
      "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE', 'DIABETES_GEST', 'HYP_TENS_PRE', 'HYP_TENS_GEST', 'PREV_BIRTH_PRETERM']\n"
     ]
    }
   ],
   "source": [
    "YNU_cols = []\n",
    "for i, s in enumerate(cols):\n",
    "    if s[1] == typ.StringType():\n",
    "        dis = births.select(s[0]) \\\n",
    "        .distinct() \\\n",
    "        .rdd \\\n",
    "        .map(lambda row: row[0]) \\\n",
    "        .collect()\n",
    "        print(dis)\n",
    "        if 'Y' in dis:\n",
    "            YNU_cols.append(s[0])\n",
    "            print(YNU_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['Y', 'N']\n",
    "['INFANT_ALIVE_AT_REPORT']\n",
    "['7', '3', '5', '6', '9', '1', '4', '2']\n",
    "['Y', 'U', 'N']\n",
    "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE']\n",
    "['Y', 'U', 'N']\n",
    "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE', 'DIABETES_GEST']\n",
    "['Y', 'U', 'N']\n",
    "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE', 'DIABETES_GEST', 'HYP_TENS_PRE']\n",
    "['Y', 'U', 'N']\n",
    "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE', 'DIABETES_GEST', 'HYP_TENS_PRE', 'HYP_TENS_GEST']\n",
    "['Y', 'U', 'N']\n",
    "['INFANT_ALIVE_AT_REPORT', 'DIABETES_PRE', 'DIABETES_GEST', 'HYP_TENS_PRE', 'HYP_TENS_GEST', 'PREV_BIRTH_PRETERM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y', 'N']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births.select('INFANT_ALIVE_AT_REPORT') \\\n",
    "        .distinct() \\\n",
    "        .rdd \\\n",
    "        .map(lambda row: row[0]) \\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7', '3', '5', '6', '9', '1', '4', '2']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births.select('BIRTH_PLACE') \\\n",
    "        .distinct() \\\n",
    "        .rdd \\\n",
    "        .map(lambda row: row[0]) \\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INFANT_NICU_ADMISSION='Y', INFANT_NICU_ADMISSION_RECODE=1),\n",
       " Row(INFANT_NICU_ADMISSION='Y', INFANT_NICU_ADMISSION_RECODE=1),\n",
       " Row(INFANT_NICU_ADMISSION='U', INFANT_NICU_ADMISSION_RECODE=0),\n",
       " Row(INFANT_NICU_ADMISSION='N', INFANT_NICU_ADMISSION_RECODE=2),\n",
       " Row(INFANT_NICU_ADMISSION='U', INFANT_NICU_ADMISSION_RECODE=0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births.select([\n",
    "    'INFANT_NICU_ADMISSION',\n",
    "    rec_integer(\n",
    "        'INFANT_NICU_ADMISSION'\n",
    "        , func.lit('YNU')).alias('INFANT_NICU_ADMISSION_RECODE')\n",
    "]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs_YNU = [\n",
    "    rec_integer(x, func.lit('YNU')).alias(x)\n",
    "    if x in YNU_cols\n",
    "    else x\n",
    "    for x in births_transformed.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column<b'recode(INFANT_ALIVE_AT_REPORT, YNU) AS `INFANT_ALIVE_AT_REPORT`'>,\n",
       " 'BIRTH_PLACE',\n",
       " 'MOTHER_AGE_YEARS',\n",
       " 'FATHER_COMBINED_AGE',\n",
       " 'CIG_BEFORE',\n",
       " 'CIG_1_TRI',\n",
       " 'CIG_2_TRI',\n",
       " 'CIG_3_TRI',\n",
       " 'MOTHER_HEIGHT_IN',\n",
       " 'MOTHER_PRE_WEIGHT',\n",
       " 'MOTHER_DELIVERY_WEIGHT',\n",
       " 'MOTHER_WEIGHT_GAIN',\n",
       " Column<b'recode(DIABETES_PRE, YNU) AS `DIABETES_PRE`'>,\n",
       " Column<b'recode(DIABETES_GEST, YNU) AS `DIABETES_GEST`'>,\n",
       " Column<b'recode(HYP_TENS_PRE, YNU) AS `HYP_TENS_PRE`'>,\n",
       " Column<b'recode(HYP_TENS_GEST, YNU) AS `HYP_TENS_GEST`'>,\n",
       " Column<b'recode(PREV_BIRTH_PRETERM, YNU) AS `PREV_BIRTH_PRETERM`'>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exprs_YNU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- YNU_cols에 있으면 사용자정의함수 처리 되고 아니면 그냥 컬럼명이 리스트에 담김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_transformed.select(exprs_YNU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------+-------------+------------------+\n",
      "|DIABETES_PRE|DIABETES_GEST|HYP_TENS_PRE|HYP_TENS_GEST|PREV_BIRTH_PRETERM|\n",
      "+------------+-------------+------------+-------------+------------------+\n",
      "|           2|            2|           2|            2|                 2|\n",
      "|           2|            2|           2|            2|                 2|\n",
      "|           2|            2|           2|            2|                 2|\n",
      "|           2|            2|           2|            2|                 1|\n",
      "|           2|            2|           2|            2|                 2|\n",
      "+------------+-------------+------------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "births_transformed.select(YNU_cols[-5:]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIABETES_PRE',\n",
       " 'DIABETES_GEST',\n",
       " 'HYP_TENS_PRE',\n",
       " 'HYP_TENS_GEST',\n",
       " 'PREV_BIRTH_PRETERM']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YNU_cols[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "\n",
    "import pyspark.mllib.stat as st\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "#     'INFANT_ALIVE_AT_REPORT', \n",
    "#     'BIRTH_PLACE', \n",
    "    'MOTHER_AGE_YEARS', \n",
    "    'FATHER_COMBINED_AGE', \n",
    "    'CIG_BEFORE', \n",
    "    'CIG_1_TRI', \n",
    "    'CIG_2_TRI', \n",
    "    'CIG_3_TRI', \n",
    "    'MOTHER_HEIGHT_IN', \n",
    "    'MOTHER_PRE_WEIGHT', \n",
    "    'MOTHER_DELIVERY_WEIGHT', \n",
    "    'MOTHER_WEIGHT_GAIN', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_rdd = births_transformed.select(numeric_cols) \\\n",
    "                .rdd.map(lambda row: [e for e in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mllib_stats = st.Statistics.colStats(numeric_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOTHER_AGE: \t28.30 \t6.08\n",
      "FATHER_COM: \t44.55 \t27.55\n",
      "CIG_BEFORE: \t1.43 \t5.18\n",
      "CIG_1_TRI: \t0.91 \t3.83\n",
      "CIG_2_TRI: \t0.70 \t3.31\n",
      "CIG_3_TRI: \t0.58 \t3.11\n",
      "MOTHER_HEI: \t65.12 \t6.45\n",
      "MOTHER_PRE: \t214.50 \t210.21\n",
      "MOTHER_DEL: \t223.63 \t180.01\n",
      "MOTHER_WEI: \t30.74 \t26.23\n"
     ]
    }
   ],
   "source": [
    "for col, m, v in zip(numeric_cols, mllib_stats.mean(), mllib_stats.variance()):\n",
    "    print( '{0:.10s}: \\t{1:.2f} \\t{2:.2f}'.format(col, m, np.sqrt(v)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- colStats()\n",
    "    - 처리된 값은 기술통계를 샘플링해서 계산한 것임\n",
    "    - 실제 데이터에서는 큰 문제는 없다. \n",
    "    - 데이터셋이 100개 미만일 경우에는 문제가 될 수 있다\n",
    "    - 본 함수는 RDD 데이터를 취해 기술통계를 계산한다.\n",
    "        - MulhvariateStahshcalSummary 객체를 리턴\n",
    "            - count() : 데이터행 갯수\n",
    "            - max() : 최대값\n",
    "            - numNonzeros() : 0 이 아닌 갯수\n",
    "            - variance() : 분산\n",
    "                - Sample variance vector.\n",
    "            - norml1() : L1-Norm 값\n",
    "                - L1 norm of each column\n",
    "            - norml2() : L2-Norm 값\n",
    "                - Euclidean magnitude of each column\n",
    "\n",
    "                - L1 Loss 이냐 L2 Loss 이냐 선택?\n",
    "                    - 직관적으로 오차의 제곱을 더함\n",
    "                    - Outlier에 대하여 더 Robust하다\n",
    "                    - Outlier가 적당히 무시되길 원하면 L1 Loss를\n",
    "                    - Outlier에 신경을 써야한다면 L2 Loss를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [e for e in births_transformed.columns if e not in numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_rdd = births_transformed.select(categorical_cols) \\\n",
    ".rdd.map(lambda row: [e for e in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFANT_ALIVE_AT_REPORT [(1, 23349), (2, 22080)]\n",
      "BIRTH_PLACE [('1', 44558), ('4', 327), ('3', 224), ('2', 136), ('7', 91), ('5', 74), ('6', 11), ('9', 8)]\n",
      "DIABETES_PRE [(2, 44689), (1, 548), (0, 192)]\n",
      "DIABETES_GEST [(2, 43259), (1, 1978), (0, 192)]\n",
      "HYP_TENS_PRE [(2, 44156), (1, 1081), (0, 192)]\n",
      "HYP_TENS_GEST [(2, 43110), (1, 2127), (0, 192)]\n",
      "PREV_BIRTH_PRETERM [(2, 42896), (1, 2341), (0, 192)]\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(categorical_cols):\n",
    "    agg = categorical_rdd.groupBy(lambda row: row[i]) \\\n",
    "                        .map( lambda row : (row[0], len(row[1])) )\n",
    "    print( col, sorted(agg.collect(), key=lambda el: el[1], reverse=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = st.Statistics.corr(numeric_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIG_BEFORE-to-CIG_1_TRI: 0.83\n",
      "CIG_BEFORE-to-CIG_2_TRI: 0.72\n",
      "CIG_BEFORE-to-CIG_3_TRI: 0.62\n",
      "CIG_1_TRI-to-CIG_BEFORE: 0.83\n",
      "CIG_1_TRI-to-CIG_2_TRI: 0.87\n",
      "CIG_1_TRI-to-CIG_3_TRI: 0.76\n",
      "CIG_2_TRI-to-CIG_BEFORE: 0.72\n",
      "CIG_2_TRI-to-CIG_1_TRI: 0.87\n",
      "CIG_2_TRI-to-CIG_3_TRI: 0.89\n",
      "CIG_3_TRI-to-CIG_BEFORE: 0.62\n",
      "CIG_3_TRI-to-CIG_1_TRI: 0.76\n",
      "CIG_3_TRI-to-CIG_2_TRI: 0.89\n",
      "MOTHER_PRE_WEIGHT-to-MOTHER_DELIVERY_WEIGHT: 0.54\n",
      "MOTHER_PRE_WEIGHT-to-MOTHER_WEIGHT_GAIN: 0.65\n",
      "MOTHER_DELIVERY_WEIGHT-to-MOTHER_PRE_WEIGHT: 0.54\n",
      "MOTHER_DELIVERY_WEIGHT-to-MOTHER_WEIGHT_GAIN: 0.60\n",
      "MOTHER_WEIGHT_GAIN-to-MOTHER_PRE_WEIGHT: 0.65\n",
      "MOTHER_WEIGHT_GAIN-to-MOTHER_DELIVERY_WEIGHT: 0.60\n"
     ]
    }
   ],
   "source": [
    "for i, el in enumerate(corrs > 0.5):\n",
    "    correlated = [\n",
    "        (numeric_cols[j], corrs[i][j])\n",
    "        for j, e in enumerate(el)\n",
    "        if e == 1.0 and j != i\n",
    "    ]\n",
    "    if len(correlated) > 0:\n",
    "        for e in correlated:\n",
    "            print( '{0}-to-{1}: {2:.2f}' \\\n",
    "                 .format(numeric_cols[i], e[0], e[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INFANT_ALIVE_AT_REPORT',\n",
       " 'BIRTH_PLACE',\n",
       " 'MOTHER_AGE_YEARS',\n",
       " 'FATHER_COMBINED_AGE',\n",
       " 'CIG_BEFORE',\n",
       " 'CIG_1_TRI',\n",
       " 'CIG_2_TRI',\n",
       " 'CIG_3_TRI',\n",
       " 'MOTHER_HEIGHT_IN',\n",
       " 'MOTHER_PRE_WEIGHT',\n",
       " 'MOTHER_DELIVERY_WEIGHT',\n",
       " 'MOTHER_WEIGHT_GAIN',\n",
       " 'DIABETES_PRE',\n",
       " 'DIABETES_GEST',\n",
       " 'HYP_TENS_PRE',\n",
       " 'HYP_TENS_GEST',\n",
       " 'PREV_BIRTH_PRETERM']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\n",
    " 'INFANT_ALIVE_AT_REPORT',\n",
    " 'BIRTH_PLACE',\n",
    " 'MOTHER_AGE_YEARS',\n",
    " 'FATHER_COMBINED_AGE',\n",
    " 'CIG_1_TRI',\n",
    " 'MOTHER_HEIGHT_IN',\n",
    " 'MOTHER_PRE_WEIGHT',\n",
    " 'DIABETES_PRE',\n",
    " 'DIABETES_GEST',\n",
    " 'HYP_TENS_PRE',\n",
    " 'HYP_TENS_GEST',\n",
    " 'PREV_BIRTH_PRETERM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_transformed.select([e for e in features_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.linalg as ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIRTH_PLACE 0.0\n",
      "DIABETES_PRE 0.0\n",
      "DIABETES_GEST 0.0\n",
      "HYP_TENS_PRE 0.0\n",
      "HYP_TENS_GEST 0.0\n",
      "PREV_BIRTH_PRETERM 0.0\n"
     ]
    }
   ],
   "source": [
    "for cat in categorical_cols[1:]:\n",
    "    agg = births_transformed.groupby('INFANT_ALIVE_AT_REPORT') \\\n",
    "                            .pivot(cat).count()\n",
    "    agg_rdd = agg.rdd.map(lambda row: (row[1:])) \\\n",
    "    .flatMap(lambda row: [0 if e == None else e for e in row]) \\\n",
    "    .collect()\n",
    "    row_length = len(agg.collect()[0])-1\n",
    "    agg = ln.Matrices.dense(row_length, 2, agg_rdd)\n",
    "    \n",
    "    test = st.Statistics.chiSqTest(agg)\n",
    "    print(cat, round(test.pValue, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matrices.dense() 함수의 파라미터 설명\n",
    "    1. 행렬에서 행의 수\n",
    "    1. 카테고리 고유값의 수\n",
    "    1. 행렬로 변환 할 값들에 대한 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.feature as ft\n",
    "import pyspark.mllib.regression as reg\n",
    "\n",
    "hashing = ft.HashingTF(7)\n",
    "births_hashed = births_transformed.rdd.map( lambda row: [\n",
    "                list(hashing.transform(row[1]).toArray())\n",
    "                    if col == 'BIRTH_PLACE'\n",
    "                    else row[i] \n",
    "                for i, col in enumerate(features_to_keep)] \n",
    "                                         ) \\\n",
    "    .map( lambda row: [[e] if type(e) == int else e for e in row] ) \\\n",
    "    .map( lambda row: [item for sublist in row for item in sublist] ) \\\n",
    "    .map( lambda row: reg.LabeledPoint(row[0], ln.Vectors.dense(row[1:])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_train, births_test = births_hashed.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1201.trainLogisticRegressionModelWithLBFGS.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\r\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:955)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.runWithMlLogisticRegression$1(LogisticRegression.scala:455)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:459)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:425)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:355)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainRegressionModel(PythonMLLibAPI.scala:92)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainLogisticRegressionModelWithLBFGS(PythonMLLibAPI.scala:308)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-25b7b786f68b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegressionWithLBFGS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mLR_Model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegressionWithLBFGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbirths_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\classification.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cls, data, iterations, initialWeights, regParam, regType, intercept, corrections, tolerance, validateData, numClasses)\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                     \u001b[0minitialWeights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumClasses\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_regression_train_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitialWeights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\regression.py\u001b[0m in \u001b[0;36m_regression_train_wrapper\u001b[1;34m(train_func, modelClass, data, initial_weights)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodelClass\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mLogisticRegressionModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         weights, intercept, numFeatures, numClasses = train_func(\n\u001b[1;32m--> 217\u001b[1;33m             data, _convert_to_vector(initial_weights))\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodelClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumFeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumClasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\classification.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(rdd, i)\u001b[0m\n\u001b[0;32m    390\u001b[0m             return callMLlibFunc(\"trainLogisticRegressionModelWithLBFGS\", rdd, int(iterations), i,\n\u001b[0;32m    391\u001b[0m                                  \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrections\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m                                  float(tolerance), bool(validateData), int(numClasses))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitialWeights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[1;34m(name, *args)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[1;34m(sc, func, *args)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1201.trainLogisticRegressionModelWithLBFGS.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\r\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:955)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.runWithMlLogisticRegression$1(LogisticRegression.scala:455)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:459)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:425)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:355)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainRegressionModel(PythonMLLibAPI.scala:92)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainLogisticRegressionModelWithLBFGS(PythonMLLibAPI.scala:308)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "LR_Model = LogisticRegressionWithLBFGS.train(births_train, iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LR_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-33556102b4e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m LR_results = (\n\u001b[0;32m      2\u001b[0m \u001b[0mbirths_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mLR_Model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbirths_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m ).map( lambda row: (row[0], row[1] * 1.0) )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LR_Model' is not defined"
     ]
    }
   ],
   "source": [
    "LR_results = (\n",
    "births_test.map(lambda row: row.label) \\\n",
    ".zip( LR_Model.predict(births_test.map(lambda row: row.features)) )\n",
    ").map( lambda row: (row[0], row[1] * 1.0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LR_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-a2d6c7b34751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLR_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'LR_results' is not defined"
     ]
    }
   ],
   "source": [
    "LR_results.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark.mllib.eveluation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-e742e5f16842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meveluation\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark.mllib.eveluation'"
     ]
    }
   ],
   "source": [
    "import pyspark.mllib.eveluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-148395098a67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLR_evaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinaryClassificationMetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLR_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'Area under PR: {0:.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLR_evaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mareaUnderPR\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'Araed under ROC: {0:.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLR_evaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mareaUnderROC\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mLR_evaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpersist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ev' is not defined"
     ]
    }
   ],
   "source": [
    "LR_evaluation = ev.BinaryClassificationMetrics(LR_results)\n",
    "\n",
    "print( 'Area under PR: {0:.2f}'.format(LR_evaluation.areaUnderPR) )\n",
    "print( 'Araed under ROC: {0:.2f}'.format(LR_evaluation.areaUnderROC) )\n",
    "LR_evaluation.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChiSqSelector()\n",
    "- 피쳐 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ft.ChiSqSelector(4).fit(births_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topFeatures_train = (\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
