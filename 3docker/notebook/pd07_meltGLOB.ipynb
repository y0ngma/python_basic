{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 해보세요!\n",
    "## melt 메서드 사용하기(151쪽)\n",
    "- 열을 행으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1개의 열만 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
      "0            Agnostic     27       34       60       81       76      137   \n",
      "1             Atheist     12       27       37       52       35       70   \n",
      "2            Buddhist     27       21       30       34       33       58   \n",
      "3            Catholic    418      617      732      670      638     1116   \n",
      "4  Don’t know/refused     15       14       15       11       10       35   \n",
      "\n",
      "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       122        109     84                  96  \n",
      "1        73         59     74                  76  \n",
      "2        62         39     53                  54  \n",
      "3       949        792    633                1489  \n",
      "4        21         17     18                 116  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pew = pd.read_csv('../data/pew.csv')\n",
    "print(pew.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n"
     ]
    }
   ],
   "source": [
    "print(pew.iloc[:, 0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion variable  value\n",
      "0            Agnostic    <$10k     27\n",
      "1             Atheist    <$10k     12\n",
      "2            Buddhist    <$10k     27\n",
      "3            Catholic    <$10k    418\n",
      "4  Don’t know/refused    <$10k     15\n"
     ]
    }
   ],
   "source": [
    "# 하나의 열에 대한것으로 변수에 담기\n",
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   $10-20k  variable               value\n",
      "0       34  religion            Agnostic\n",
      "1       27  religion             Atheist\n",
      "2       21  religion            Buddhist\n",
      "3      617  religion            Catholic\n",
      "4       14  religion  Don’t know/refused\n"
     ]
    }
   ],
   "source": [
    "pew_long1 = pd.melt(pew, id_vars = '$10-20k')\n",
    "print(pew_long1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion income  count\n",
      "0            Agnostic  <$10k     27\n",
      "1             Atheist  <$10k     12\n",
      "2            Buddhist  <$10k     27\n",
      "3            Catholic  <$10k    418\n",
      "4  Don’t know/refused  <$10k     15\n"
     ]
    }
   ],
   "source": [
    "pew_long = pd.melt(pew, id_vars='religion', var_name='income', value_name='count')\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 317 entries, 0 to 316\n",
      "Data columns (total 81 columns):\n",
      "year            317 non-null int64\n",
      "artist          317 non-null object\n",
      "track           317 non-null object\n",
      "time            317 non-null object\n",
      "date.entered    317 non-null object\n",
      "wk1             317 non-null int64\n",
      "wk2             312 non-null float64\n",
      "wk3             307 non-null float64\n",
      "wk4             300 non-null float64\n",
      "wk5             292 non-null float64\n",
      "wk6             280 non-null float64\n",
      "wk7             269 non-null float64\n",
      "wk8             260 non-null float64\n",
      "wk9             253 non-null float64\n",
      "wk10            244 non-null float64\n",
      "wk11            236 non-null float64\n",
      "wk12            222 non-null float64\n",
      "wk13            210 non-null float64\n",
      "wk14            204 non-null float64\n",
      "wk15            197 non-null float64\n",
      "wk16            182 non-null float64\n",
      "wk17            177 non-null float64\n",
      "wk18            166 non-null float64\n",
      "wk19            156 non-null float64\n",
      "wk20            146 non-null float64\n",
      "wk21            65 non-null float64\n",
      "wk22            55 non-null float64\n",
      "wk23            48 non-null float64\n",
      "wk24            46 non-null float64\n",
      "wk25            38 non-null float64\n",
      "wk26            36 non-null float64\n",
      "wk27            29 non-null float64\n",
      "wk28            24 non-null float64\n",
      "wk29            20 non-null float64\n",
      "wk30            20 non-null float64\n",
      "wk31            19 non-null float64\n",
      "wk32            18 non-null float64\n",
      "wk33            12 non-null float64\n",
      "wk34            10 non-null float64\n",
      "wk35            9 non-null float64\n",
      "wk36            9 non-null float64\n",
      "wk37            9 non-null float64\n",
      "wk38            8 non-null float64\n",
      "wk39            8 non-null float64\n",
      "wk40            7 non-null float64\n",
      "wk41            7 non-null float64\n",
      "wk42            6 non-null float64\n",
      "wk43            6 non-null float64\n",
      "wk44            6 non-null float64\n",
      "wk45            5 non-null float64\n",
      "wk46            5 non-null float64\n",
      "wk47            5 non-null float64\n",
      "wk48            4 non-null float64\n",
      "wk49            4 non-null float64\n",
      "wk50            4 non-null float64\n",
      "wk51            4 non-null float64\n",
      "wk52            4 non-null float64\n",
      "wk53            4 non-null float64\n",
      "wk54            2 non-null float64\n",
      "wk55            2 non-null float64\n",
      "wk56            2 non-null float64\n",
      "wk57            2 non-null float64\n",
      "wk58            2 non-null float64\n",
      "wk59            2 non-null float64\n",
      "wk60            2 non-null float64\n",
      "wk61            2 non-null float64\n",
      "wk62            2 non-null float64\n",
      "wk63            2 non-null float64\n",
      "wk64            2 non-null float64\n",
      "wk65            1 non-null float64\n",
      "wk66            0 non-null float64\n",
      "wk67            0 non-null float64\n",
      "wk68            0 non-null float64\n",
      "wk69            0 non-null float64\n",
      "wk70            0 non-null float64\n",
      "wk71            0 non-null float64\n",
      "wk72            0 non-null float64\n",
      "wk73            0 non-null float64\n",
      "wk74            0 non-null float64\n",
      "wk75            0 non-null float64\n",
      "wk76            0 non-null float64\n",
      "dtypes: float64(75), int64(2), object(4)\n",
      "memory usage: 200.7+ KB\n"
     ]
    }
   ],
   "source": [
    "billboard.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'],\n",
    "                         # id_vars 파라미터는 안바꾸겠다\n",
    "                         var_name='week', value_name='rating')\n",
    "\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time date.entered week  \\\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   2000-08-19  wk1   \n",
      "6  2000         A*Teens            Dancing Queen  3:44   2000-07-08  wk1   \n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   2000-01-29  wk1   \n",
      "8  2000         Aaliyah                Try Again  4:03   2000-03-18  wk1   \n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   2000-08-26  wk1   \n",
      "\n",
      "   rating  \n",
      "5    51.0  \n",
      "6    97.0  \n",
      "7    84.0  \n",
      "8    59.0  \n",
      "9    76.0  \n"
     ]
    }
   ],
   "source": [
    "print(billboard_long.iloc[5:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 해보세요!\n",
    "## ebola 데이터 집합 살펴보기(155쪽)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ebola = pd.read_csv('../data/country_timeseries.csv')\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.iloc[:5, [0, 1, 2, 3, 10, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "ebola_long = pd.melt(ebola, id_vars=['Date', 'Day'])\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 해보세요!\n",
    "## 열 이름 분리하고 데이터프레임에 추가하기(156쪽)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Cases, Guinea]\n",
      "1    [Cases, Guinea]\n",
      "2    [Cases, Guinea]\n",
      "3    [Cases, Guinea]\n",
      "4    [Cases, Guinea]\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "variable_split = ebola_long.variable.str.split('_')\n",
    "# .variable = ['variable'] 특정 컬럼 가져오기\n",
    "# str로 split 매소드 호출 Cases_Guinea -> 리스트에 나누기\n",
    "\n",
    "print(variable_split[:5])\n",
    "# 다음처럼 Series(열안에) 리스트로 담겨져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(variable_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Cases', 'Guinea']\n",
      "Cases\n",
      "['Cases', 'Guinea']\n",
      "0        Cases\n",
      "1        Cases\n",
      "2        Cases\n",
      "3        Cases\n",
      "4        Cases\n",
      "         ...  \n",
      "1947    Deaths\n",
      "1948    Deaths\n",
      "1949    Deaths\n",
      "1950    Deaths\n",
      "1951    Deaths\n",
      "Name: variable, Length: 1952, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(variable_split[0]))\n",
    "print(variable_split[0])\n",
    "print(variable_split[0][0])\n",
    "print(variable_split.get(0))\n",
    "print(variable_split.str.get(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Cases\n",
      "1    Cases\n",
      "2    Cases\n",
      "3    Cases\n",
      "4    Cases\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "status_values = variable_split.str.get(0) \n",
    "country_values = variable_split.str.get(1)\n",
    "\n",
    "print(status_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947    Deaths\n",
      "1948    Deaths\n",
      "1949    Deaths\n",
      "1950    Deaths\n",
      "1951    Deaths\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(status_values[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Guinea\n",
      "1    Guinea\n",
      "2    Guinea\n",
      "3    Guinea\n",
      "4    Guinea\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947    Mali\n",
      "1948    Mali\n",
      "1949    Mali\n",
      "1950    Mali\n",
      "1951    Mali\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "# 추출한 열의 인덱스는 데이터프레임이랑 동일하므로 서로 동일\n",
    "ebola_long['status'] = status_values \n",
    "ebola_long['country'] = country_values\n",
    "\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 알아두면 좋아요!\n",
    "## concat 메서드를 응용하여 데이터프레임에 열 추가하기(159쪽)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "# axis=1 옆으로 붙이기\n",
    "variable_split = ebola_long.variable.str.split('_', expand=True) \n",
    "variable_split.columns = ['status', 'country'] \n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)\n",
    "\n",
    "print(ebola_parsed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 기상 데이터의 여러 열을 하나로 정리하기  ─ melt, pivot_table 메서드(160쪽)\n",
    "- 열을 행으로 melt\n",
    "- 행을 열로  pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  d7\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN NaN\n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN NaN\n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN NaN\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv('../data/weather.csv') \n",
    "print(weather.iloc[:5, :11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  year  month element day  temp\n",
      "0   MX17004  2010      1    tmax  d1   NaN\n",
      "1   MX17004  2010      1    tmin  d1   NaN\n",
      "2   MX17004  2010      2    tmax  d1   NaN\n",
      "3   MX17004  2010      2    tmin  d1   NaN\n",
      "4   MX17004  2010      3    tmax  d1   NaN\n",
      "5   MX17004  2010      3    tmin  d1   NaN\n",
      "6   MX17004  2010      4    tmax  d1   NaN\n",
      "7   MX17004  2010      4    tmin  d1   NaN\n",
      "8   MX17004  2010      5    tmax  d1   NaN\n",
      "9   MX17004  2010      5    tmin  d1   NaN\n",
      "10  MX17004  2010      6    tmax  d1   NaN\n",
      "11  MX17004  2010      6    tmin  d1   NaN\n",
      "12  MX17004  2010      7    tmax  d1   NaN\n",
      "13  MX17004  2010      7    tmin  d1   NaN\n",
      "14  MX17004  2010      8    tmax  d1   NaN\n",
      "15  MX17004  2010      8    tmin  d1   NaN\n",
      "16  MX17004  2010     10    tmax  d1   NaN\n",
      "17  MX17004  2010     10    tmin  d1   NaN\n",
      "18  MX17004  2010     11    tmax  d1   NaN\n",
      "19  MX17004  2010     11    tmin  d1   NaN\n",
      "20  MX17004  2010     12    tmax  d1  29.9\n",
      "21  MX17004  2010     12    tmin  d1  13.8\n",
      "22  MX17004  2010      1    tmax  d2   NaN\n",
      "23  MX17004  2010      1    tmin  d2   NaN\n",
      "24  MX17004  2010      2    tmax  d2  27.3\n",
      "25  MX17004  2010      2    tmin  d2  14.4\n",
      "26  MX17004  2010      3    tmax  d2   NaN\n",
      "27  MX17004  2010      3    tmin  d2   NaN\n",
      "28  MX17004  2010      4    tmax  d2   NaN\n",
      "29  MX17004  2010      4    tmin  d2   NaN\n",
      "30  MX17004  2010      5    tmax  d2   NaN\n",
      "31  MX17004  2010      5    tmin  d2   NaN\n",
      "32  MX17004  2010      6    tmax  d2   NaN\n",
      "33  MX17004  2010      6    tmin  d2   NaN\n",
      "34  MX17004  2010      7    tmax  d2   NaN\n",
      "35  MX17004  2010      7    tmin  d2   NaN\n",
      "36  MX17004  2010      8    tmax  d2   NaN\n",
      "37  MX17004  2010      8    tmin  d2   NaN\n",
      "38  MX17004  2010     10    tmax  d2   NaN\n",
      "39  MX17004  2010     10    tmin  d2   NaN\n",
      "40  MX17004  2010     11    tmax  d2  31.3\n",
      "41  MX17004  2010     11    tmin  d2  16.3\n",
      "42  MX17004  2010     12    tmax  d2   NaN\n",
      "43  MX17004  2010     12    tmin  d2   NaN\n",
      "44  MX17004  2010      1    tmax  d3   NaN\n",
      "45  MX17004  2010      1    tmin  d3   NaN\n",
      "46  MX17004  2010      2    tmax  d3  24.1\n",
      "47  MX17004  2010      2    tmin  d3  14.4\n",
      "48  MX17004  2010      3    tmax  d3   NaN\n",
      "49  MX17004  2010      3    tmin  d3   NaN\n"
     ]
    }
   ],
   "source": [
    "weather_melt = pd.melt(weather, id_vars=['id', 'year', 'month', 'element'], var_name='day', \n",
    "                       value_name='temp') \n",
    "print(weather_melt.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin\n",
      "id      year month day            \n",
      "MX17004 2010 1     d30  27.8  14.5\n",
      "             2     d11  29.7  13.4\n",
      "                   d2   27.3  14.4\n",
      "                   d23  29.9  10.7\n",
      "                   d3   24.1  14.4\n",
      "             3     d10  34.5  16.8\n",
      "                   d16  31.1  17.6\n",
      "                   d5   32.1  14.2\n",
      "             4     d27  36.3  16.7\n",
      "             5     d27  33.2  18.2\n",
      "             6     d17  28.0  17.5\n",
      "                   d29  30.1  18.0\n",
      "             7     d3   28.6  17.5\n",
      "                   d14  29.9  16.5\n",
      "             8     d23  26.4  15.0\n",
      "                   d5   29.6  15.8\n",
      "                   d29  28.0  15.3\n",
      "                   d13  29.8  16.5\n",
      "                   d25  29.7  15.6\n",
      "                   d31  25.4  15.4\n",
      "                   d8   29.0  17.3\n",
      "             10    d5   27.0  14.0\n",
      "                   d14  29.5  13.0\n",
      "                   d15  28.7  10.5\n",
      "                   d28  31.2  15.0\n",
      "                   d7   28.1  12.9\n",
      "             11    d2   31.3  16.3\n",
      "                   d5   26.3   7.9\n",
      "                   d27  27.7  14.2\n",
      "                   d26  28.1  12.1\n",
      "                   d4   27.2  12.0\n",
      "             12    d1   29.9  13.8\n",
      "                   d6   27.8  10.5\n"
     ]
    }
   ],
   "source": [
    "# 컬럼의 하부컬럼은 시계열이 아니라 category타입 데이터 이면 좋다.\n",
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id', 'year', 'month', 'day'], \n",
    "    columns='element', \n",
    "    values='temp'\n",
    ")\n",
    "\n",
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element           tmax                                                        \\\n",
      "month               1     2     3     4     5     6     7     8     10    11   \n",
      "id      year day                                                               \n",
      "MX17004 2010 d1    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d10   NaN   NaN  34.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d11   NaN  29.7   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d13   NaN   NaN   NaN   NaN   NaN   NaN   NaN  29.8   NaN   NaN   \n",
      "             d14   NaN   NaN   NaN   NaN   NaN   NaN  29.9   NaN  29.5   NaN   \n",
      "             d15   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  28.7   NaN   \n",
      "             d16   NaN   NaN  31.1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d17   NaN   NaN   NaN   NaN   NaN  28.0   NaN   NaN   NaN   NaN   \n",
      "             d2    NaN  27.3   NaN   NaN   NaN   NaN   NaN   NaN   NaN  31.3   \n",
      "             d23   NaN  29.9   NaN   NaN   NaN   NaN   NaN  26.4   NaN   NaN   \n",
      "             d25   NaN   NaN   NaN   NaN   NaN   NaN   NaN  29.7   NaN   NaN   \n",
      "             d26   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  28.1   \n",
      "             d27   NaN   NaN   NaN  36.3  33.2   NaN   NaN   NaN   NaN  27.7   \n",
      "             d28   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  31.2   NaN   \n",
      "             d29   NaN   NaN   NaN   NaN   NaN  30.1   NaN  28.0   NaN   NaN   \n",
      "             d3    NaN  24.1   NaN   NaN   NaN   NaN  28.6   NaN   NaN   NaN   \n",
      "             d30  27.8   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d31   NaN   NaN   NaN   NaN   NaN   NaN   NaN  25.4   NaN   NaN   \n",
      "             d4    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  27.2   \n",
      "             d5    NaN   NaN  32.1   NaN   NaN   NaN   NaN  29.6  27.0  26.3   \n",
      "             d6    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d7    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  28.1   NaN   \n",
      "             d8    NaN   NaN   NaN   NaN   NaN   NaN   NaN  29.0   NaN   NaN   \n",
      "\n",
      "element           ...  tmin                                                  \\\n",
      "month             ...    2     3     4     5     6     7     8     10    11   \n",
      "id      year day  ...                                                         \n",
      "MX17004 2010 d1   ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d10  ...   NaN  16.8   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d11  ...  13.4   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d13  ...   NaN   NaN   NaN   NaN   NaN   NaN  16.5   NaN   NaN   \n",
      "             d14  ...   NaN   NaN   NaN   NaN   NaN  16.5   NaN  13.0   NaN   \n",
      "             d15  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN  10.5   NaN   \n",
      "             d16  ...   NaN  17.6   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d17  ...   NaN   NaN   NaN   NaN  17.5   NaN   NaN   NaN   NaN   \n",
      "             d2   ...  14.4   NaN   NaN   NaN   NaN   NaN   NaN   NaN  16.3   \n",
      "             d23  ...  10.7   NaN   NaN   NaN   NaN   NaN  15.0   NaN   NaN   \n",
      "             d25  ...   NaN   NaN   NaN   NaN   NaN   NaN  15.6   NaN   NaN   \n",
      "             d26  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  12.1   \n",
      "             d27  ...   NaN   NaN  16.7  18.2   NaN   NaN   NaN   NaN  14.2   \n",
      "             d28  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN  15.0   NaN   \n",
      "             d29  ...   NaN   NaN   NaN   NaN  18.0   NaN  15.3   NaN   NaN   \n",
      "             d3   ...  14.4   NaN   NaN   NaN   NaN  17.5   NaN   NaN   NaN   \n",
      "             d30  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d31  ...   NaN   NaN   NaN   NaN   NaN   NaN  15.4   NaN   NaN   \n",
      "             d4   ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  12.0   \n",
      "             d5   ...   NaN  14.2   NaN   NaN   NaN   NaN  15.8  14.0   7.9   \n",
      "             d6   ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "             d7   ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN  12.9   NaN   \n",
      "             d8   ...   NaN   NaN   NaN   NaN   NaN   NaN  17.3   NaN   NaN   \n",
      "\n",
      "element                 \n",
      "month               12  \n",
      "id      year day        \n",
      "MX17004 2010 d1   13.8  \n",
      "             d10   NaN  \n",
      "             d11   NaN  \n",
      "             d13   NaN  \n",
      "             d14   NaN  \n",
      "             d15   NaN  \n",
      "             d16   NaN  \n",
      "             d17   NaN  \n",
      "             d2    NaN  \n",
      "             d23   NaN  \n",
      "             d25   NaN  \n",
      "             d26   NaN  \n",
      "             d27   NaN  \n",
      "             d28   NaN  \n",
      "             d29   NaN  \n",
      "             d3    NaN  \n",
      "             d30   NaN  \n",
      "             d31   NaN  \n",
      "             d4    NaN  \n",
      "             d5    NaN  \n",
      "             d6   10.5  \n",
      "             d7    NaN  \n",
      "             d8    NaN  \n",
      "\n",
      "[23 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id', 'year', 'day'], \n",
    "    columns=['element', 'month'], \n",
    "    values='temp'\n",
    ")\n",
    "\n",
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  day tmax                                ...  tmin  \\\n",
      "month                          1     2     3   4   5   6     7  ...     2   \n",
      "0        MX17004  2010   d1  NaN   NaN   NaN NaN NaN NaN   NaN  ...   NaN   \n",
      "1        MX17004  2010  d10  NaN   NaN  34.5 NaN NaN NaN   NaN  ...   NaN   \n",
      "2        MX17004  2010  d11  NaN  29.7   NaN NaN NaN NaN   NaN  ...  13.4   \n",
      "3        MX17004  2010  d13  NaN   NaN   NaN NaN NaN NaN   NaN  ...   NaN   \n",
      "4        MX17004  2010  d14  NaN   NaN   NaN NaN NaN NaN  29.9  ...   NaN   \n",
      "\n",
      "element                                                \n",
      "month       3   4   5   6     7     8    10  11    12  \n",
      "0         NaN NaN NaN NaN   NaN   NaN   NaN NaN  13.8  \n",
      "1        16.8 NaN NaN NaN   NaN   NaN   NaN NaN   NaN  \n",
      "2         NaN NaN NaN NaN   NaN   NaN   NaN NaN   NaN  \n",
      "3         NaN NaN NaN NaN   NaN  16.5   NaN NaN   NaN  \n",
      "4         NaN NaN NaN NaN  16.5   NaN  13.0 NaN   NaN  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "weather_tidy_flat = weather_tidy.reset_index() \n",
    "print(weather_tidy_flat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 해보세요!\n",
    "## 빌보드 차트의 중복 데이터 처리하기(163쪽)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 7)\n",
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'],\n",
    "                         var_name='week', value_name='rating')\n",
    "\n",
    "print(billboard_long.shape)\n",
    "\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5    67.0\n"
     ]
    }
   ],
   "source": [
    "# data[\"track\"] == 'Loser' 컬럼명이 loser인것\n",
    "print(billboard_long[billboard_long.track == 'Loser'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 4)\n"
     ]
    }
   ],
   "source": [
    "billboard_songs = billboard_long[['year', 'artist', 'track', 'time']] \n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 4)\n"
     ]
    }
   ],
   "source": [
    "# 빌보드차트 데이터 특성상 주별 중복데이터 많음. 그러한 열제외한 데이터를 drop_duplicates() 이용\n",
    "billboard_songs = billboard_songs.drop_duplicates() \n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "# 인덱스 말고 중복데이터 제외한 번호 열 생성해서 붙이기\n",
    "billboard_songs['id'] = range(len(billboard_songs)) \n",
    "print(billboard_songs.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1830992, 7)\n"
     ]
    }
   ],
   "source": [
    "billboard_ratings = billboard_long.merge( billboard_songs, on=['year', 'artist', 'track', 'time']) \n",
    "print(billboard_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year artist                    track  time date.entered week  rating\n",
      "0  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "2  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "3  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "4  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 해보세요! GLOB\n",
    "## 뉴욕 택시 데이터 준비(166쪽)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import urllib.request\n",
    "\n",
    "# # 네트워크 상태에 따라 5 ~ 15분이 소요됩니다.\n",
    "# with open('../data/raw_data_urls.txt', 'r') as data_urls:\n",
    "#     for line, url in enumerate(data_urls):\n",
    "#         if line == 5:\n",
    "#             break \n",
    "#         fn = url.split('/')[-1].strip()\n",
    "#         fp = os.path.join('', '../data', fn)\n",
    "#         print(url)\n",
    "#         print(fp)\n",
    "#         urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/fhv_tripdata_2015-05.csv', '../data/fhv_tripdata_2015-03.csv', '../data/fhv_tripdata_2015-02.csv', '../data/fhv_tripdata_2015-04.csv', '../data/fhv_tripdata_2015-01.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "nyc_taxi_data = glob.glob('../data/fhv_tripdata*') \n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi1 = pd.read_csv(nyc_taxi_data[0]) \n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1]) \n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2]) \n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3]) \n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-05-01 04:30:00         NaN\n",
      "1               B00001  2015-05-01 05:00:00         NaN\n",
      "2               B00001  2015-05-01 05:05:00         NaN\n",
      "3               B00001  2015-05-01 06:15:00         NaN\n",
      "4               B00001  2015-05-01 06:15:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00029  2015-03-01 00:02:00       213.0\n",
      "1               B00029  2015-03-01 00:03:00        51.0\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-02-01 00:00:00         NaN\n",
      "1               B00013  2015-02-01 00:01:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-04-01 04:30:00         NaN\n",
      "1               B00001  2015-04-01 06:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.head()) \n",
    "print(taxi2.head(2)) \n",
    "print(taxi3.head(n=2)) \n",
    "print(taxi4.head(n=2)) \n",
    "print(taxi5.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4296067, 3)\n",
      "(3281427, 3)\n",
      "(3126401, 3)\n",
      "(3917789, 3)\n",
      "(2746033, 3)\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.shape) \n",
    "print(taxi2.shape) \n",
    "print(taxi3.shape) \n",
    "print(taxi4.shape) \n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "taxi = pd.concat([taxi1, taxi2, taxi3, taxi4, taxi5])\n",
    "\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 알아두면 좋아요!\n",
    "## 반복문으로 데이터 준비하기(169쪽)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "list_taxi_df = [] \n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    # print(csv_filename)\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df) \n",
    "\n",
    "print(len(list_taxi_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(list_taxi_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-05-01 04:30:00         NaN\n",
      "1               B00001  2015-05-01 05:00:00         NaN\n",
      "2               B00001  2015-05-01 05:05:00         NaN\n",
      "3               B00001  2015-05-01 06:15:00         NaN\n",
      "4               B00001  2015-05-01 06:15:00         NaN\n"
     ]
    }
   ],
   "source": [
    "print(list_taxi_df[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "taxi_loop_concat = pd.concat(list_taxi_df) \n",
    "print(taxi_loop_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(taxi.equals(taxi_loop_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
